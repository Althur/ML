{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "HOUSING_FILE = 'housing.csv'\n",
    "\n",
    "def load_housing_data(housing_file=HOUSING_FILE):\n",
    "    return pd.read_csv(housing_file)\n",
    "\n",
    "\n",
    "housing = load_housing_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntype(housing)\\nhousing.info()\\nhousing.head(n=10)\\nhousing.describe()\\nhousing[\"ocean_proximity\"].value_counts()\\ntype(housing[\"ocean_proximity\"])\\nhousing.hist(bins=50, figsize=(20, 15))\\nplt.show()\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# analyse data\n",
    "\"\"\"\n",
    "type(housing)\n",
    "housing.info()\n",
    "housing.head(n=10)\n",
    "housing.describe()\n",
    "housing[\"ocean_proximity\"].value_counts()\n",
    "type(housing[\"ocean_proximity\"])\n",
    "housing.hist(bins=50, figsize=(20, 15))\n",
    "plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_test split\n",
    "\n",
    "train_set, test_set = train_test_split(\n",
    "    housing,\n",
    "    test_size=0.2,\n",
    "    random_state=RANDOM_SEED,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntrain_set.corr()\\nprint(\"{} train + {} test\".format(len(train_set), len(test_set)))\\nprint(\"{} total\".format(len(train_set)+len(test_set)))\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# analyse correlation\n",
    "\n",
    "\"\"\"\n",
    "train_set.corr()\n",
    "print(\"{} train + {} test\".format(len(train_set), len(test_set)))\n",
    "print(\"{} total\".format(len(train_set)+len(test_set)))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove dependent variable (remove o label que queremos treinar)\n",
    "\n",
    "X_train = train_set.drop(columns=[\"median_house_value\"]) \n",
    "y_train = train_set[\"median_house_value\"]   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 16512 entries, 17606 to 15775\n",
      "Data columns (total 11 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   longitude           16512 non-null  float64\n",
      " 1   latitude            16512 non-null  float64\n",
      " 2   housing_median_age  16512 non-null  float64\n",
      " 3   total_rooms         16512 non-null  float64\n",
      " 4   total_bedrooms      16354 non-null  float64\n",
      " 5   population          16512 non-null  float64\n",
      " 6   households          16512 non-null  float64\n",
      " 7   median_income       16512 non-null  float64\n",
      " 8   median_house_value  16512 non-null  float64\n",
      " 9   ocean_proximity     16512 non-null  object \n",
      " 10  income_cat          16512 non-null  float64\n",
      "dtypes: float64(10), object(1)\n",
      "memory usage: 1.5+ MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 16512 entries, 17606 to 15775\n",
      "Data columns (total 10 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   longitude           16512 non-null  float64\n",
      " 1   latitude            16512 non-null  float64\n",
      " 2   housing_median_age  16512 non-null  float64\n",
      " 3   total_rooms         16512 non-null  float64\n",
      " 4   total_bedrooms      16354 non-null  float64\n",
      " 5   population          16512 non-null  float64\n",
      " 6   households          16512 non-null  float64\n",
      " 7   median_income       16512 non-null  float64\n",
      " 8   median_house_value  16512 non-null  float64\n",
      " 9   ocean_proximity     16512 non-null  object \n",
      "dtypes: float64(9), object(1)\n",
      "memory usage: 1.4+ MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4128 entries, 5241 to 2398\n",
      "Data columns (total 10 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   longitude           4128 non-null   float64\n",
      " 1   latitude            4128 non-null   float64\n",
      " 2   housing_median_age  4128 non-null   float64\n",
      " 3   total_rooms         4128 non-null   float64\n",
      " 4   total_bedrooms      4079 non-null   float64\n",
      " 5   population          4128 non-null   float64\n",
      " 6   households          4128 non-null   float64\n",
      " 7   median_income       4128 non-null   float64\n",
      " 8   median_house_value  4128 non-null   float64\n",
      " 9   ocean_proximity     4128 non-null   object \n",
      "dtypes: float64(9), object(1)\n",
      "memory usage: 354.8+ KB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# para criar novas colunas com base nos dados atuais\n",
    "# Realizar a separação estratificada do dataset com base numa variável categórica \"criada\" para relacionar a renda\n",
    "# média das regiões das casa. \n",
    "\n",
    "# Constroi uma coluna nova com categorias de renda fictícias.\n",
    "housing[\"income_cat\"] = np.ceil(housing[\"median_income\"] / 1.5)\n",
    "housing[\"income_cat\"].where(housing[\"income_cat\"] < 5, 5.0, inplace=True)\n",
    "\n",
    "# Divide, de modo estratificado, o conjunto de dados.\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "split = StratifiedShuffleSplit(\n",
    "    n_splits=1,\n",
    "    test_size=0.2,\n",
    "    random_state=RANDOM_SEED)\n",
    "for train_index, test_index in split.split(housing, housing[\"income_cat\"]):\n",
    "    strat_train_set = housing.loc[train_index]\n",
    "    strat_test_set = housing.loc[test_index]\n",
    "    \n",
    "strat_train_set[\"income_cat\"].value_counts() / len(strat_train_set)\n",
    "strat_test_set[\"income_cat\"].value_counts() / len(strat_test_set)\n",
    "strat_train_set.info()\n",
    "\n",
    "# Remove a coluna nova, que foi adicionada apenas temporariamente.\n",
    "strat_train_set.drop([\"income_cat\"], axis=1, inplace=True)\n",
    "strat_test_set.drop([\"income_cat\"], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "strat_train_set.info()\n",
    "strat_test_set.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analise de correlação ... na aula 02 e 03 temos exemplos \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estatísticas do Imputer:\n",
      "[-118.51     34.26     29.     2119.5     433.     1164.      408.\n",
      "    3.5409]\n",
      "Medianas\n",
      "[-118.51     34.26     29.     2119.5     433.     1164.      408.\n",
      "    3.5409]\n"
     ]
    }
   ],
   "source": [
    "# preparando os dados para o modelo\n",
    "\n",
    "# Variáveis independentes: dataset original menos a coluna de valores dependentes.\n",
    "housing = strat_train_set.drop(\"median_house_value\", axis=1)\n",
    "\n",
    "# Variável dependente, também chamada de label.\n",
    "housing_labels = strat_train_set[\"median_house_value\"].copy()\n",
    "\n",
    "df = housing.copy()\n",
    "df['median_house_value'] = housing_labels\n",
    "\n",
    "\n",
    "# resolvendo o problema dos valores faltantes com imputer\n",
    "\n",
    "# Antes de treinar o SimpleImputer, remover a coluna de dados categóricos. O dataset resultante tem apenas\n",
    "# as variáveis independentes numéricas.\n",
    "housing_num = housing.drop(\"ocean_proximity\", axis=1)\n",
    "\n",
    "# Cria um imputer que substitui células inválidas (NaN) pela mediana dos valores da coluna à qual a célula pertence.\n",
    "imputer = SimpleImputer(strategy=\"median\")\n",
    "\n",
    "# Agora treinar o Imputer. Isto vai causar o cálculo da mediana de cada coluna,\n",
    "# que ficará armazenado no Imputer para uso futuro.\n",
    "imputer.fit(housing_num)\n",
    "\n",
    "# O Imputer agora tem as estatísticas desejadas armazenadas.\n",
    "print(\"Estatísticas do Imputer:\")\n",
    "print(imputer.statistics_)\n",
    "\n",
    "# Compare com as medianas do DataFrame:\n",
    "print(\"Medianas\")\n",
    "print(housing_num.median().values)\n",
    "\n",
    "\n",
    "# Aplicar o Imputer aos nossos dados. O valor de retorno é um ndarray do NumPy.\n",
    "temp = imputer.transform(housing_num)\n",
    "#print(type(temp))\n",
    "\n",
    "# Trabalhar com DataFrames geralmente é mais legal - dá para referenciar colunas por nome, ao invés de indices.\n",
    "# Vamos transformar de volta o ndarray em DataFrame.\n",
    "housing_tr = pd.DataFrame(temp, columns=housing_num.columns)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Codificando variáveis categóricas\n",
    "\n",
    "# Separar apenas as variáveis categóricas (neste caso temos apenas uma).\n",
    "housing_cat = housing[[\"ocean_proximity\"]]\n",
    "#print(type(housing_cat))\n",
    "#print(housing_cat.head())\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "housing_cat_encoded = ordinal_encoder.fit_transform(housing_cat)\n",
    "#housing_cat_encoded[:10]\n",
    "#ordinal_encoder.categories_\n",
    "\n",
    "# criando o codificador \n",
    "\n",
    "encoder = OneHotEncoder(categories=\"auto\")\n",
    "\n",
    "# Aprende a codificação e já aplica a mesma ao dataset fornecido. Todo transformador no sklearn\n",
    "# tem os métodos fit() para aprender a transformação, e transform() para aplicá-la.\n",
    "# O método fit_transform() faz os dois atos em sequência.\n",
    "housing_cat_1hot = encoder.fit_transform(housing_cat)\n",
    "\n",
    "# print(housing_cat_1hot.toarray()[:5])\n",
    "# encoder.categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>ocean_proximity</th>\n",
       "      <th>rooms_per_household</th>\n",
       "      <th>population_per_household</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-121.89</td>\n",
       "      <td>37.29</td>\n",
       "      <td>38</td>\n",
       "      <td>1568</td>\n",
       "      <td>351</td>\n",
       "      <td>710</td>\n",
       "      <td>339</td>\n",
       "      <td>2.7042</td>\n",
       "      <td>&lt;1H OCEAN</td>\n",
       "      <td>4.62537</td>\n",
       "      <td>2.0944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-121.93</td>\n",
       "      <td>37.05</td>\n",
       "      <td>14</td>\n",
       "      <td>679</td>\n",
       "      <td>108</td>\n",
       "      <td>306</td>\n",
       "      <td>113</td>\n",
       "      <td>6.4214</td>\n",
       "      <td>&lt;1H OCEAN</td>\n",
       "      <td>6.00885</td>\n",
       "      <td>2.70796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-117.2</td>\n",
       "      <td>32.77</td>\n",
       "      <td>31</td>\n",
       "      <td>1952</td>\n",
       "      <td>471</td>\n",
       "      <td>936</td>\n",
       "      <td>462</td>\n",
       "      <td>2.8621</td>\n",
       "      <td>NEAR OCEAN</td>\n",
       "      <td>4.22511</td>\n",
       "      <td>2.02597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-119.61</td>\n",
       "      <td>36.31</td>\n",
       "      <td>25</td>\n",
       "      <td>1847</td>\n",
       "      <td>371</td>\n",
       "      <td>1460</td>\n",
       "      <td>353</td>\n",
       "      <td>1.8839</td>\n",
       "      <td>INLAND</td>\n",
       "      <td>5.23229</td>\n",
       "      <td>4.13598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-118.59</td>\n",
       "      <td>34.23</td>\n",
       "      <td>17</td>\n",
       "      <td>6592</td>\n",
       "      <td>1525</td>\n",
       "      <td>4459</td>\n",
       "      <td>1463</td>\n",
       "      <td>3.0347</td>\n",
       "      <td>&lt;1H OCEAN</td>\n",
       "      <td>4.50581</td>\n",
       "      <td>3.04785</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  longitude latitude housing_median_age total_rooms total_bedrooms population  \\\n",
       "0   -121.89    37.29                 38        1568            351        710   \n",
       "1   -121.93    37.05                 14         679            108        306   \n",
       "2    -117.2    32.77                 31        1952            471        936   \n",
       "3   -119.61    36.31                 25        1847            371       1460   \n",
       "4   -118.59    34.23                 17        6592           1525       4459   \n",
       "\n",
       "  households median_income ocean_proximity rooms_per_household  \\\n",
       "0        339        2.7042       <1H OCEAN             4.62537   \n",
       "1        113        6.4214       <1H OCEAN             6.00885   \n",
       "2        462        2.8621      NEAR OCEAN             4.22511   \n",
       "3        353        1.8839          INLAND             5.23229   \n",
       "4       1463        3.0347       <1H OCEAN             4.50581   \n",
       "\n",
       "  population_per_household  \n",
       "0                   2.0944  \n",
       "1                  2.70796  \n",
       "2                  2.02597  \n",
       "3                  4.13598  \n",
       "4                  3.04785  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# criando um Transformer \n",
    "\n",
    "class CombinedAttributesAdder(BaseEstimator, TransformerMixin):\n",
    "    # column index\n",
    "    rooms_ix, bedrooms_ix, population_ix, household_ix = 3, 4, 5, 6\n",
    "\n",
    "    def __init__(self, add_bedrooms_per_room=True):  # no *args or **kargs\n",
    "        self.add_bedrooms_per_room = add_bedrooms_per_room\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self  # nothing else to do\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        rooms_per_household = (X[:, CombinedAttributesAdder.rooms_ix] /\n",
    "                               X[:, CombinedAttributesAdder.household_ix])\n",
    "        population_per_household = (\n",
    "            X[:, CombinedAttributesAdder.population_ix] /\n",
    "            X[:, CombinedAttributesAdder.household_ix])\n",
    "\n",
    "        if self.add_bedrooms_per_room:\n",
    "            bedrooms_per_room = (X[:, CombinedAttributesAdder.bedrooms_ix] /\n",
    "                                 X[:, CombinedAttributesAdder.rooms_ix])\n",
    "            return np.c_[X, rooms_per_household, population_per_household,\n",
    "                         bedrooms_per_room]\n",
    "        else:\n",
    "            return np.c_[X, rooms_per_household, population_per_household]\n",
    "\n",
    "\n",
    "attr_adder = CombinedAttributesAdder(add_bedrooms_per_room=False)  #\"\"\"N entendi pq n funciona com valor True\"\"\"\n",
    "housing_extra_attribs = attr_adder.transform(housing.values)\n",
    "\n",
    "# Transformando em DataFrame, porque DataFrames são mais amigáveis.\n",
    "columns_housing_extra_attribs = list(housing.columns) + [\n",
    "    \"rooms_per_household\",\n",
    "    \"population_per_household\",\n",
    "]\n",
    "housing_extra_attribs = pd.DataFrame(housing_extra_attribs,\n",
    "                                     columns=columns_housing_extra_attribs)\n",
    "housing_extra_attribs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criando pipelines\n",
    "\n",
    "meu_imputer = SimpleImputer(strategy=\"median\")\n",
    "meu_adder = CombinedAttributesAdder()\n",
    "meu_scaler = StandardScaler()\n",
    "\n",
    "\n",
    "# numerical pipeline\n",
    "num_pipeline = Pipeline([\n",
    "    (\"imputer\", meu_imputer),\n",
    "    (\"attribs_adder\", meu_adder),\n",
    "    (\"std_scaler\", meu_scaler),\n",
    "])\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "# outra forma de fazer...\n",
    "num_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"attribs_adder\", CombinedAttributesAdder()),\n",
    "    (\"std_scaler\", StandardScaler()),\n",
    "])\n",
    "\n",
    "housing_num_tr = num_pipeline.fit_transform(housing_num)\n",
    "housing_num_tr\"\"\"\n",
    "\n",
    "housing_num_tr = num_pipeline.fit_transform(housing_num)\n",
    "#housing_num_tr\n",
    "\n",
    "\n",
    "# categorical pipeline\n",
    "cat_pipeline = Pipeline([\n",
    "    (\"cat_encoder\", OneHotEncoder(sparse=False)),\n",
    "])\n",
    "\n",
    "housing_cat_tr = cat_pipeline.fit_transform(housing_cat)\n",
    "#housing_cat_tr\n",
    "\n",
    "\n",
    "# full pipeline\n",
    "num_attribs = list(housing_num)\n",
    "cat_attribs = [\"ocean_proximity\"]\n",
    "\n",
    "full_pipeline = ColumnTransformer([\n",
    "    (\"num\", num_pipeline, num_attribs),\n",
    "    (\"cat\", OneHotEncoder(sparse=False), cat_attribs),\n",
    "])\n",
    "\n",
    "housing_prepared = full_pipeline.fit_transform(housing)\n",
    "#housing_prepared[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predição: [210644.6  317768.81 210956.43  59218.99 189747.56]\n",
      "Original: [286600. 340600. 196900.  46300. 254500.]\n",
      "Regressão linear: RMSE = 68628.20\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    1.651200e+04\n",
       "mean    -2.253114e-11\n",
       "std      6.863028e+04\n",
       "min     -6.184707e+05\n",
       "25%     -4.232504e+04\n",
       "50%     -1.068880e+04\n",
       "75%      2.824534e+04\n",
       "max      8.157162e+05\n",
       "Name: median_house_value, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# criando modelos \n",
    "\n",
    "# Regressor Linear\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(housing_prepared, housing_labels)\n",
    "\n",
    "\n",
    "# Seleciona 5 pontos do conjunto de treinamento.\n",
    "some_data = housing.iloc[:5]\n",
    "some_labels = housing_labels.iloc[:5]\n",
    "some_data_prepared = full_pipeline.transform(some_data)\n",
    "\n",
    "\n",
    "# Para obter as previsões, basta chamar o método predict()\n",
    "predicted_labels = lin_reg.predict(some_data_prepared)\n",
    "print(\"Predição: {}\".format(predicted_labels.round(decimals=2)))\n",
    "\n",
    "# Compare com os valores originais:\n",
    "print(\"Original: {}\".format(some_labels.values.round(decimals=2)))\n",
    "\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "housing_predictions = lin_reg.predict(housing_prepared)\n",
    "lin_mse = mean_squared_error(housing_labels, housing_predictions)\n",
    "lin_rmse = np.sqrt(lin_mse)\n",
    "print(\"Regressão linear: RMSE = {:.2f}\".format(lin_rmse))\n",
    "\n",
    "\n",
    "residuo = housing_labels - housing_predictions\n",
    "#plt.hist(residuo, bins=50)\n",
    "pd.Series(residuo).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predição: [286600. 340600. 196900.  46300. 254500.]\n",
      "Original: [286600. 340600. 196900.  46300. 254500.]\n",
      "Regressão linear: RMSE = 0.00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\nClássico over-fitting\\n\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# criando modelo\n",
    "# arvore de decisão\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "tree_reg = DecisionTreeRegressor(random_state=RANDOM_SEED)\n",
    "tree_reg.fit(housing_prepared, housing_labels)\n",
    "\n",
    "predicted_labels = tree_reg.predict(some_data_prepared)\n",
    "print(\"Predição: {}\".format(predicted_labels))\n",
    "print(\"Original: {}\".format(some_labels.values))\n",
    "\n",
    "housing_predictions = tree_reg.predict(housing_prepared)\n",
    "tree_mse = mean_squared_error(housing_labels, housing_predictions)\n",
    "tree_rmse = np.sqrt(tree_mse)\n",
    "print(\"Regressão linear: RMSE = {:.2f}\".format(tree_rmse))\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "Clássico over-fitting\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melhorando a avaliação usando o Validação Cruzada (Cross-Validation)\n",
    "\n",
    "\n",
    "# por simplicidade, não usaremos neste exemplo a divisão estratificada\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(housing_prepared,\n",
    "                                                    housing_labels,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regressão linear: RMSE = 69392.52\n",
      "Regressão árvore de decisão: RMSE = 71023.94\n"
     ]
    }
   ],
   "source": [
    "lin_reg.fit(X_train, y_train)\n",
    "\n",
    "y_pred = lin_reg.predict(X_test)\n",
    "lin_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(\"Regressão linear: RMSE = {:.2f}\".format(lin_rmse))\n",
    "\n",
    "tree_reg.fit(X_train, y_train)\n",
    "\n",
    "y_pred = tree_reg.predict(X_test)\n",
    "tree_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(\"Regressão árvore de decisão: RMSE = {:.2f}\".format(tree_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regressão random forest: RMSE = 52601.87\n"
     ]
    }
   ],
   "source": [
    "# Criando um modelo \n",
    "\n",
    "# Regressor Random Forest \n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "forest_reg = RandomForestRegressor(n_estimators=10, random_state=RANDOM_SEED)\n",
    "\n",
    "forest_reg.fit(X_train, y_train)\n",
    "\n",
    "y_pred = forest_reg.predict(X_test)\n",
    "forest_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(\"Regressão random forest: RMSE = {:.2f}\".format(forest_rmse))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear\n",
      "Scores: [66782.74 66960.12 70347.95 74739.57 68031.13 71193.84 64969.63 68281.61\n",
      " 71552.92 67665.1 ]\n",
      "Mean: 69052.46136345083\n",
      "Standard deviation: 2731.674001798348\n",
      "arvore\n",
      "Scores: [70194.34 66855.16 72432.58 70758.74 71115.88 75585.14 70262.86 70273.63\n",
      " 75366.88 71231.66]\n",
      "Mean: 71407.68766037929\n",
      "Standard deviation: 2439.4345041191004\n",
      "random forest\n",
      "Scores: [51646.45 48940.6  53050.86 54408.99 50922.15 56482.51 51864.52 49760.85\n",
      " 55434.22 53326.1 ]\n",
      "Mean: 52583.72407377466\n",
      "Standard deviation: 2298.353351147122\n"
     ]
    }
   ],
   "source": [
    "# como saber se esses resultados não são pura sorte?\n",
    "# Seguinte ferramenta do sci-kit learn\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# scores lineares\n",
    "lin_scores = cross_val_score(\n",
    "    lin_reg,\n",
    "    housing_prepared,\n",
    "    housing_labels,\n",
    "    scoring=\"neg_mean_squared_error\",\n",
    "    cv=10,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "lin_rmse_scores = np.sqrt(-lin_scores)\n",
    "\n",
    "# scores arvore\n",
    "tree_scores = cross_val_score(\n",
    "    tree_reg,\n",
    "    housing_prepared,\n",
    "    housing_labels,\n",
    "    scoring=\"neg_mean_squared_error\",\n",
    "    cv=10,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "tree_rmse_scores = np.sqrt(-tree_scores)\n",
    "\n",
    "\n",
    "# scores random forest\n",
    "forest_scores = cross_val_score(\n",
    "    forest_reg,\n",
    "    housing_prepared,\n",
    "    housing_labels,\n",
    "    scoring=\"neg_mean_squared_error\",\n",
    "    cv=10,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "forest_rmse_scores = np.sqrt(-forest_scores)\n",
    "\n",
    "\n",
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores.round(decimals=2))\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())\n",
    "\n",
    "print('linear')\n",
    "display_scores(lin_rmse_scores)\n",
    "print('arvore')\n",
    "display_scores(tree_rmse_scores)\n",
    "print('random forest')\n",
    "display_scores(forest_rmse_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tempo gasto: 57.78 s\n"
     ]
    }
   ],
   "source": [
    "# Encontrando o  melhor conjunto de hiper-parâmetros \n",
    "\n",
    "\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "\n",
    "param_grid = [\n",
    "    # try 6 (2×3) combinations of hyperparameters.\n",
    "    {\n",
    "        \"n_estimators\": [5, 10, 15, 30, 40],\n",
    "        \"max_features\": [4, 6, 8, 10, 12],\n",
    "    },\n",
    "    # then try 4 (1x2×2) combinations with bootstrap set as False.\n",
    "    {\n",
    "        \"bootstrap\": [False],\n",
    "        \"n_estimators\": [3, 10, 18, 27],\n",
    "        \"max_features\": [3, 4, 8, 15],\n",
    "    },\n",
    "]\n",
    "\n",
    "forest_reg = RandomForestRegressor(random_state=RANDOM_SEED)\n",
    "\n",
    "# train across 5 folds, that's a total of (6+4)*5=50 rounds of training.\n",
    "grid_search = GridSearchCV(\n",
    "    forest_reg,\n",
    "    param_grid,\n",
    "    cv=5,\n",
    "    scoring=\"neg_mean_squared_error\",\n",
    "    return_train_score=True,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "t1 = time.perf_counter()\n",
    "grid_search.fit(housing_prepared, housing_labels)\n",
    "t2 = time.perf_counter()\n",
    "\n",
    "print(f\"Tempo gasto: {t2 - t1:.2f} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': False, 'max_features': 8, 'n_estimators': 27}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=False, max_features=8, n_estimators=27,\n",
       "                      random_state=42)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# melhor modelo treinado\n",
    "\n",
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56405.55344386644 {'max_features': 4, 'n_estimators': 5}\n",
      "52741.04704299915 {'max_features': 4, 'n_estimators': 10}\n",
      "51775.16663319472 {'max_features': 4, 'n_estimators': 15}\n",
      "50377.40461678399 {'max_features': 4, 'n_estimators': 30}\n",
      "50143.14410447875 {'max_features': 4, 'n_estimators': 40}\n",
      "54906.23833596068 {'max_features': 6, 'n_estimators': 5}\n",
      "52006.19873526564 {'max_features': 6, 'n_estimators': 10}\n",
      "51077.825559965466 {'max_features': 6, 'n_estimators': 15}\n",
      "50146.51167415009 {'max_features': 6, 'n_estimators': 30}\n",
      "49892.295944853344 {'max_features': 6, 'n_estimators': 40}\n",
      "54242.75738147613 {'max_features': 8, 'n_estimators': 5}\n",
      "51711.127883959234 {'max_features': 8, 'n_estimators': 10}\n",
      "50710.992838563994 {'max_features': 8, 'n_estimators': 15}\n",
      "49682.273345071546 {'max_features': 8, 'n_estimators': 30}\n",
      "49504.61171066941 {'max_features': 8, 'n_estimators': 40}\n",
      "55422.14720483451 {'max_features': 10, 'n_estimators': 5}\n",
      "52243.03120763529 {'max_features': 10, 'n_estimators': 10}\n",
      "51181.11588840536 {'max_features': 10, 'n_estimators': 15}\n",
      "50248.50830956178 {'max_features': 10, 'n_estimators': 30}\n",
      "49936.64370838097 {'max_features': 10, 'n_estimators': 40}\n",
      "55290.92886613099 {'max_features': 12, 'n_estimators': 5}\n",
      "52467.394325940615 {'max_features': 12, 'n_estimators': 10}\n",
      "51211.20999561363 {'max_features': 12, 'n_estimators': 15}\n",
      "50175.90329245697 {'max_features': 12, 'n_estimators': 30}\n",
      "49993.98047305722 {'max_features': 12, 'n_estimators': 40}\n",
      "59470.40652318466 {'bootstrap': False, 'max_features': 3, 'n_estimators': 3}\n",
      "52724.9822587892 {'bootstrap': False, 'max_features': 3, 'n_estimators': 10}\n",
      "51406.68834155682 {'bootstrap': False, 'max_features': 3, 'n_estimators': 18}\n",
      "50854.34230582445 {'bootstrap': False, 'max_features': 3, 'n_estimators': 27}\n",
      "57490.5691951261 {'bootstrap': False, 'max_features': 4, 'n_estimators': 3}\n",
      "51009.495668875716 {'bootstrap': False, 'max_features': 4, 'n_estimators': 10}\n",
      "50017.631442357306 {'bootstrap': False, 'max_features': 4, 'n_estimators': 18}\n",
      "49378.947759224524 {'bootstrap': False, 'max_features': 4, 'n_estimators': 27}\n",
      "57465.303977081014 {'bootstrap': False, 'max_features': 8, 'n_estimators': 3}\n",
      "50948.86760059858 {'bootstrap': False, 'max_features': 8, 'n_estimators': 10}\n",
      "49513.87073423319 {'bootstrap': False, 'max_features': 8, 'n_estimators': 18}\n",
      "48979.09870747144 {'bootstrap': False, 'max_features': 8, 'n_estimators': 27}\n",
      "61196.57417836973 {'bootstrap': False, 'max_features': 15, 'n_estimators': 3}\n",
      "57092.24157055083 {'bootstrap': False, 'max_features': 15, 'n_estimators': 10}\n",
      "58101.300512092654 {'bootstrap': False, 'max_features': 15, 'n_estimators': 18}\n",
      "57708.53903581077 {'bootstrap': False, 'max_features': 15, 'n_estimators': 27}\n"
     ]
    }
   ],
   "source": [
    "cvres = grid_search.cv_results_\n",
    "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "    print(np.sqrt(-mean_score), params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.36646090386578456, 'median_income'),\n",
       " (0.16499671600370852, 'INLAND'),\n",
       " (0.10732516127770518, 'pop_per_hhold'),\n",
       " (0.07775302201262438, 'longitude'),\n",
       " (0.06821700672673928, 'latitude'),\n",
       " (0.053368610739487794, 'rooms_per_hhold'),\n",
       " (0.051785354880582044, 'bedrooms_per_room'),\n",
       " (0.04245236014079516, 'housing_median_age'),\n",
       " (0.015069172233995457, 'total_rooms'),\n",
       " (0.014042557999651956, 'households'),\n",
       " (0.013854304754456974, 'population'),\n",
       " (0.013552068991095461, 'total_bedrooms'),\n",
       " (0.006569084170173832, '<1H OCEAN'),\n",
       " (0.002696539911105351, 'NEAR OCEAN'),\n",
       " (0.0018048974941087441, 'NEAR BAY'),\n",
       " (5.223879798543149e-05, 'ISLAND')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# analise da importância das caracteri(features)\n",
    "\n",
    "feature_importances = grid_search.best_estimator_.feature_importances_\n",
    "#feature_importances\n",
    "extra_attribs = [\"rooms_per_hhold\", \"pop_per_hhold\", \"bedrooms_per_room\"]\n",
    "cat_encoder = cat_pipeline.named_steps[\"cat_encoder\"]\n",
    "cat_one_hot_attribs = list(cat_encoder.categories_[0])\n",
    "attributes = num_attribs + extra_attribs + cat_one_hot_attribs\n",
    "sorted(zip(feature_importances, attributes), reverse=True)\n",
    "\n",
    "# como podemos observar, os extra atrr foram acertados, estão dentre os top-7 mais importantes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['longitude', 'latitude', 'housing_median_age', 'total_rooms', 'total_bedrooms', 'population', 'households', 'median_income']\n"
     ]
    }
   ],
   "source": [
    "print(num_attribs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7.77530220e-02, 6.82170067e-02, 4.24523601e-02, 1.50691722e-02,\n",
       "       1.35520690e-02, 1.38543048e-02, 1.40425580e-02, 3.66460904e-01,\n",
       "       5.33686107e-02, 1.07325161e-01, 5.17853549e-02, 6.56908417e-03,\n",
       "       1.64996716e-01, 5.22387980e-05, 1.80489749e-03, 2.69653991e-03])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE = 47220.87908393705\n"
     ]
    }
   ],
   "source": [
    "# Validação conjunto de testes\n",
    "\n",
    "final_model = grid_search.best_estimator_\n",
    "\n",
    "X_test = strat_test_set.drop(\"median_house_value\", axis=1)\n",
    "y_test = strat_test_set[\"median_house_value\"].copy()\n",
    "\n",
    "X_test_prepared = full_pipeline.transform(X_test)\n",
    "final_predictions = final_model.predict(X_test_prepared)\n",
    "\n",
    "final_mse = mean_squared_error(y_test, final_predictions)\n",
    "final_rmse = np.sqrt(final_mse)\n",
    "\n",
    "print(\"RMSE = {}\".format(final_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
